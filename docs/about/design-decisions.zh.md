# 设计决策

本文档解释了 clinvk 开发过程中的关键设计决策及其背后的原理。

## 为什么使用子进程执行而不是 SDK？

### 决策

clinvk 将 AI CLI 工具作为子进程执行，而不是直接使用它们的 SDK。

### 原理

1. **零配置**：CLI 工具自动处理认证、API 密钥和配置
2. **始终最新**：SDK API 变更时无需更新 clinvk
3. **功能对等**：CLI 工具通常有 SDK 中没有的功能
4. **会话管理**：利用 CLI 工具内置的会话处理
5. **简洁性**：一个抽象层而不是多个 SDK 集成

### 权衡

| 方面 | 子进程方式 | SDK 方式 |
|------|-----------|----------|
| 启动时间 | 略慢 | 更快 |
| 依赖 | 更少 | 更多库 |
| 维护 | 更低 | 更高 |
| 功能访问 | 完整 CLI 功能 | SDK 受限 |
| 认证 | CLI 处理 | 需要代码 |

## 为什么有多种 API 格式？

### 决策

clinvk 提供三类 API 端点：OpenAI 兼容、Anthropic 兼容和自定义 REST。

### 原理

1. **OpenAI 兼容** (`/openai/v1/*`)
   - 大多数 AI 框架使用 OpenAI SDK 格式
   - LangChain、LangGraph 开箱即用
   - 轻松从 OpenAI 迁移到其他后端

2. **Anthropic 兼容** (`/anthropic/v1/*`)
   - 为 Anthropic SDK 用户提供原生支持
   - 完整的 Claude 特定功能
   - Messages API 格式

3. **自定义 REST** (`/api/v1/*`)
   - 更简单、更直接的接口
   - clinvk 特定功能（并行、链式）
   - 最适合 Claude Code Skills 集成

## 会话管理设计

### 决策

会话按后端跟踪，支持可配置的持久化模式。

### 考虑的选项

1. **全局会话** - 所有后端共享单一会话
2. **按后端会话** - 每个后端有独立会话
3. **混合模式** - 共享上下文，后端特定状态

### 为什么选择按后端？

- 不同后端有不兼容的会话格式
- 避免后端间的上下文污染
- 用户更容易理解
- 符合 CLI 工具的原生行为

### 会话模式

| 模式 | 持久化 | 用例 |
|------|--------|------|
| `ephemeral` | 无 | 无状态 API 调用 |
| `auto` | 自动命名 | 默认交互使用 |
| `named` | 用户指定 | 长期运行的项目 |

## 并行与链式执行

### 决策

提供并行（并发）和链式（顺序）两种执行模式。

### 设计原则

**并行执行：**
```
任务 A ─┬─→ 后端 1 ──┬─→ 结果 A
        ├─→ 后端 2 ──┤   结果 B
        └─→ 后端 3 ──┘   结果 C
```

- 独立任务并发运行
- 快速失败选项提高效率
- 完成时聚合结果

**链式执行：**
```
输入 → 后端 1 → {{previous}} → 后端 2 → {{previous}} → 后端 3 → 输出
```

- 顺序流水线
- 每步通过 `{{previous}}` 访问上一步输出
- 支持多阶段工作流

## 配置级联

### 决策

配置遵循级联规则：CLI 参数 → 环境变量 → 配置文件 → 默认值。

### 原理

1. **可预测的覆盖** - 高优先级来源总是获胜
2. **环境友好** - 在容器和 CI/CD 中表现良好
3. **用户可控** - 无需更改文件即可轻松覆盖
4. **安全默认值** - 无指定时使用安全配置

### 解析示例

```yaml
# 配置文件：~/.clinvk/config.yaml
backend: claude
timeout: 60

# 环境变量
CLINVK_TIMEOUT=120

# CLI
clinvk --backend codex "prompt"

# 结果：backend=codex (CLI), timeout=120 (env)
```

## HTTP 服务器设计

### 决策

单个二进制提供所有端点服务，支持优雅关闭。

### 关键特性

1. **标准 HTTP/1.1** - 最大兼容性
2. **SSE 流式传输** - Server-Sent Events 实现实时输出
3. **CORS 可配置** - 支持浏览器客户端
4. **健康端点** - `/health` 用于负载均衡器

### 为什么不用 gRPC？

- HTTP 得到普遍支持
- 浏览器兼容性很重要
- 使用 curl 调试更简单
- 大多数 AI SDK 使用 HTTP/REST

## 错误处理哲学

### 决策

传播带上下文的错误，优雅地失败。

### 原则

1. **保留 CLI 退出码** - 准确传播后端错误
2. **结构化错误** - 带错误详情的 JSON 格式
3. **优雅降级** - 并行模式下返回部分结果
4. **详细日志** - 需要时提供调试信息

### 错误响应格式

```json
{
  "error": {
    "type": "backend_error",
    "message": "Claude CLI 以代码 1 退出",
    "backend": "claude",
    "details": "速率限制已超"
  }
}
```

## 未来考虑

### MCP 服务器支持

我们正在评估添加 Model Context Protocol (MCP) 服务器支持以实现：
- 与 Claude Desktop 直接集成
- 标准化的工具调用接口
- 生态系统兼容性

### 额外后端

后端抽象允许在新 AI CLI 可用时添加它们。新后端的要求：
- CLI 支持非交互模式
- 结构化输出（首选 JSON）
- 会话管理（可选但首选）

## 总结

| 决策 | 选择 | 关键原因 |
|------|------|----------|
| 执行 | 子进程 | 零配置，始终最新 |
| API 格式 | 多种 | 框架兼容性 |
| 会话 | 按后端 | 隔离和简洁 |
| 编排 | 并行 + 链式 | 不同工作流需求 |
| 配置 | 级联 | 可预测，环境友好 |
| 服务器 | HTTP/SSE | 通用兼容性 |
